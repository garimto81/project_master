/**
 * Logic Flow API - Code Analysis (Level 1-A: Big Picture)
 * PRD v6.3 Section 1.2: ë¹„ê°œë°œì ì¹œí™”ì  ì‹œê°í™” ì „ëµ
 *
 * v6.3 ì—…ë°ì´íŠ¸:
 * - ì‹¤ì œ import ë¬¸ íŒŒì‹±ìœ¼ë¡œ ì˜ì¡´ì„± ì¶”ì¶œ
 * - ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
 * - ë¯¸ì‚¬ìš© íŒŒì¼ íƒì§€
 * - ë¶„ì„ í†µê³„ ì¶”ê°€
 *
 * v6.4 ì„±ëŠ¥ ìµœì í™”:
 * - ë³‘ë ¬ ì²˜ë¦¬ (5ë°° ì†ë„ í–¥ìƒ)
 * - ìƒ˜í”Œë§ ê¸°ë°˜ ë¶„ì„ (90% ì‹œê°„ ë‹¨ì¶•)
 * - ì„œë²„ì‚¬ì´ë“œ ìºì‹± (ì¬ë°©ë¬¸ ì¦‰ì‹œ ë¡œë“œ)
 */

import { NextRequest, NextResponse } from 'next/server'
import { getGitHubTokenFromSession } from '@/lib/auth'
import { analysisCache, treeCache, issuesCache, GitHubTreeItem } from '@/lib/analysis-cache'

interface Layer {
  name: string
  displayName: string
  modules: string[]
  description: string
}

interface Connection {
  from: string
  to: string
  type: 'call' | 'fetch' | 'import' | 'event'
  label?: string
  imports?: string[]  // v6.3: ì‹¤ì œ import í•­ëª©
}

interface RiskPoint {
  location: string
  function: string
  risk: 'high' | 'medium' | 'low'
  reason: string
  suggestion: string
}

// v6.3: ìˆœí™˜ ì˜ì¡´ì„±
interface CircularDependency {
  cycle: string[]
  severity: 'warning' | 'error'
  suggestion: string
}

// v6.3: ë¶„ì„ í†µê³„
interface AnalysisStats {
  totalFiles: number
  analyzedFiles: number
  totalDependencies: number
  circularCount: number
  unusedCount: number
}

// GitHub API ì‘ë‹µ íƒ€ì… (GitHubTreeItemì€ @/lib/analysis-cacheì—ì„œ import)
interface GitHubTreeResponse {
  tree: GitHubTreeItem[]
  truncated?: boolean
}

interface GitHubIssue {
  number: number
  title: string
  body: string | null
  labels: Array<{ name: string }>
}

interface AnalyzeResponse {
  repo: string
  level: 'overview'
  analysis_method: 'import-parsing' | 'sampling-import-parsing'  // v6.4: ìƒ˜í”Œë§ í¬í•¨
  data_flow: {
    entry_points: string[]
    layers: Layer[]
    connections: Connection[]
  }
  circular_dependencies: CircularDependency[]  // v6.3
  unused_files: string[]  // v6.3
  risk_points: RiskPoint[]
  issues: Array<{
    number: number
    title: string
    labels: string[]
    related_layer?: string
  }>
  mermaid_code: string
  stats: AnalysisStats  // v6.3
  summary: string
}

// íŒŒì¼ ê²½ë¡œì—ì„œ ë ˆì´ì–´ ì¶”ë¡ 
function inferLayer(path: string): string {
  const lowerPath = path.toLowerCase()

  // UI ë ˆì´ì–´
  if (lowerPath.includes('component') || lowerPath.includes('page') ||
      lowerPath.includes('view') || lowerPath.includes('ui') ||
      lowerPath.match(/\.(tsx|jsx)$/)) {
    return 'ui'
  }

  // API/Server ë ˆì´ì–´
  if (lowerPath.includes('api') || lowerPath.includes('route') ||
      lowerPath.includes('server') || lowerPath.includes('endpoint')) {
    return 'server'
  }

  // Data ë ˆì´ì–´
  if (lowerPath.includes('model') || lowerPath.includes('schema') ||
      lowerPath.includes('database') || lowerPath.includes('db') ||
      lowerPath.includes('store') || lowerPath.includes('state')) {
    return 'data'
  }

  // Logic ë ˆì´ì–´ (ê¸°ë³¸)
  if (lowerPath.includes('service') || lowerPath.includes('util') ||
      lowerPath.includes('lib') || lowerPath.includes('helper') ||
      lowerPath.includes('hook')) {
    return 'logic'
  }

  return 'logic' // ê¸°ë³¸ê°’
}

// ì½”ë“œì—ì„œ ìœ„í—˜ íŒ¨í„´ ê°ì§€
function detectRiskPatterns(content: string, path: string): RiskPoint[] {
  const risks: RiskPoint[] = []
  const lines = content.split('\n')

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i]
    const lineNum = i + 1

    // íŒ¨í„´ 1: try-catch ì—†ëŠ” fetch/API í˜¸ì¶œ
    if ((line.includes('fetch(') || line.includes('axios') || line.includes('.get(') || line.includes('.post(')) &&
        !lines.slice(Math.max(0, i - 5), i).some(l => l.includes('try'))) {
      // ë‹¤ìŒ 5ì¤„ ì•ˆì— catchê°€ ìˆëŠ”ì§€ í™•ì¸
      const hasNearCatch = lines.slice(i, Math.min(lines.length, i + 10)).some(l => l.includes('catch'))
      if (!hasNearCatch) {
        risks.push({
          location: `${path}:${lineNum}`,
          function: extractFunctionName(lines, i),
          risk: 'high',
          reason: 'API í˜¸ì¶œ í›„ ì—ëŸ¬ ì²˜ë¦¬ ì—†ìŒ',
          suggestion: 'try-catch ì¶”ê°€ ë˜ëŠ” .catch() í•¸ë“¤ëŸ¬ ì¶”ê°€',
        })
      }
    }

    // íŒ¨í„´ 2: null/undefined ì²´í¬ ì—†ì´ í”„ë¡œí¼í‹° ì ‘ê·¼
    const unsafeAccess = line.match(/(\w+)\.(\w+)\.(\w+)/)
    if (unsafeAccess && !line.includes('?.') && !line.includes('&&') &&
        !line.includes('if') && !line.includes('||')) {
      risks.push({
        location: `${path}:${lineNum}`,
        function: extractFunctionName(lines, i),
        risk: 'medium',
        reason: 'ê¹Šì€ í”„ë¡œí¼í‹° ì ‘ê·¼ ì‹œ null ì²´í¬ ì—†ìŒ',
        suggestion: 'ì˜µì…”ë„ ì²´ì´ë‹(?.) ì‚¬ìš© ê¶Œì¥',
      })
    }

    // íŒ¨í„´ 3: console.log ë‚¨ì•„ìˆìŒ (í”„ë¡œë•ì…˜ ì½”ë“œ)
    if (line.includes('console.log') && !path.includes('test') && !path.includes('spec')) {
      risks.push({
        location: `${path}:${lineNum}`,
        function: extractFunctionName(lines, i),
        risk: 'low',
        reason: 'ë””ë²„ê·¸ ë¡œê·¸ê°€ í”„ë¡œë•ì…˜ ì½”ë“œì— ë‚¨ì•„ìˆìŒ',
        suggestion: 'ë°°í¬ ì „ console.log ì œê±° í•„ìš”',
      })
    }
  }

  return risks.slice(0, 5) // íŒŒì¼ë‹¹ ìµœëŒ€ 5ê°œ
}

function extractFunctionName(lines: string[], currentIndex: number): string {
  // ìœ„ë¡œ ì˜¬ë¼ê°€ë©´ì„œ í•¨ìˆ˜ ì •ì˜ ì°¾ê¸°
  for (let i = currentIndex; i >= Math.max(0, currentIndex - 20); i--) {
    const line = lines[i]
    const funcMatch = line.match(/(?:function|const|let|var)\s+(\w+)|(\w+)\s*[=:]\s*(?:async\s*)?\(/)
    if (funcMatch) {
      return funcMatch[1] || funcMatch[2] || 'anonymous'
    }
  }
  return 'anonymous'
}

// v6.3: ì½”ë“œì—ì„œ import ë¬¸ ì¶”ì¶œ
function extractImports(content: string, filePath: string): Array<{ from: string; to: string; imports: string[] }> {
  const imports: Array<{ from: string; to: string; imports: string[] }> = []
  const lines = content.split('\n')

  for (const line of lines) {
    // import { x, y } from './module'
    const namedImportMatch = line.match(/import\s*\{([^}]+)\}\s*from\s*['"]([^'"]+)['"]/)
    if (namedImportMatch) {
      const importedItems = namedImportMatch[1].split(',').map(s => s.trim().split(' as ')[0])
      const modulePath = namedImportMatch[2]
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, modulePath),
        imports: importedItems,
      })
      continue
    }

    // import x from './module'
    const defaultImportMatch = line.match(/import\s+(\w+)\s+from\s*['"]([^'"]+)['"]/)
    if (defaultImportMatch) {
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, defaultImportMatch[2]),
        imports: [defaultImportMatch[1]],
      })
      continue
    }

    // import * as x from './module'
    const namespaceImportMatch = line.match(/import\s*\*\s*as\s+(\w+)\s+from\s*['"]([^'"]+)['"]/)
    if (namespaceImportMatch) {
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, namespaceImportMatch[2]),
        imports: [`* as ${namespaceImportMatch[1]}`],
      })
      continue
    }

    // import './module' (side effect)
    const sideEffectMatch = line.match(/import\s*['"]([^'"]+)['"]/)
    if (sideEffectMatch && !line.includes('from')) {
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, sideEffectMatch[1]),
        imports: ['(side effect)'],
      })
    }
  }

  return imports
}

// import ê²½ë¡œ í•´ì„
function resolveImportPath(fromPath: string, importPath: string): string {
  // ìƒëŒ€ ê²½ë¡œê°€ ì•„ë‹Œ ê²½ìš° (íŒ¨í‚¤ì§€ import)
  if (!importPath.startsWith('.') && !importPath.startsWith('@/')) {
    return `node_modules/${importPath}`
  }

  // @/ alias ì²˜ë¦¬
  if (importPath.startsWith('@/')) {
    return importPath.replace('@/', 'src/')
  }

  // ìƒëŒ€ ê²½ë¡œ í•´ì„ (ê°„ë‹¨í•œ ë²„ì „)
  const fromDir = fromPath.split('/').slice(0, -1).join('/')
  const parts = importPath.split('/')
  const result = fromDir.split('/')

  for (const part of parts) {
    if (part === '..') {
      result.pop()
    } else if (part !== '.') {
      result.push(part)
    }
  }

  return result.join('/')
}

// v6.3: ìˆœí™˜ ì˜ì¡´ì„± íƒì§€ (DFS)
function detectCircularDependencies(
  imports: Array<{ from: string; to: string }>
): string[][] {
  const graph = new Map<string, string[]>()

  // ê·¸ë˜í”„ êµ¬ì¶•
  for (const imp of imports) {
    if (!graph.has(imp.from)) {
      graph.set(imp.from, [])
    }
    graph.get(imp.from)!.push(imp.to)
  }

  const cycles: string[][] = []
  const visited = new Set<string>()
  const recursionStack = new Set<string>()

  function dfs(node: string, path: string[]): void {
    if (recursionStack.has(node)) {
      // ìˆœí™˜ ë°œê²¬
      const cycleStart = path.indexOf(node)
      if (cycleStart !== -1) {
        cycles.push([...path.slice(cycleStart), node])
      }
      return
    }

    if (visited.has(node)) {
      return
    }

    visited.add(node)
    recursionStack.add(node)

    const neighbors = graph.get(node) || []
    for (const neighbor of neighbors) {
      dfs(neighbor, [...path, node])
    }

    recursionStack.delete(node)
  }

  for (const node of graph.keys()) {
    dfs(node, [])
  }

  return cycles
}

// v6.3: ë¯¸ì‚¬ìš© íŒŒì¼ íƒì§€
function detectUnusedFiles(
  allFiles: string[],
  imports: Array<{ from: string; to: string }>,
  entryPoints: string[]
): string[] {
  const importedFiles = new Set<string>()

  // ëª¨ë“  importëœ íŒŒì¼ ìˆ˜ì§‘
  for (const imp of imports) {
    importedFiles.add(imp.to)
  }

  // ì§„ì…ì  ì¶”ê°€
  for (const entry of entryPoints) {
    importedFiles.add(entry)
  }

  // importë˜ì§€ ì•Šì€ íŒŒì¼ ì°¾ê¸°
  return allFiles.filter(file => {
    const normalizedFile = file.replace(/\.(tsx?|jsx?)$/, '')
    return !importedFiles.has(normalizedFile) &&
           !importedFiles.has(file) &&
           !file.includes('test') &&
           !file.includes('spec') &&
           !file.includes('.d.ts')
  })
}

async function analyzeCodebase(request: NextRequest, params: { repo?: string; path?: string; depth?: string; include_risk?: boolean; skipCache?: boolean }) {
  try {
    const { repo, path = 'src/', depth = 'medium', include_risk = true, skipCache = false } = params

    if (!repo) {
      return NextResponse.json({ error: 'repo parameter required' }, { status: 400 })
    }

    // ì¸ì¦ í™•ì¸
    const { token } = await getGitHubTokenFromSession()

    if (!token) {
      return NextResponse.json({ error: 'GitHub ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.' }, { status: 401 })
    }

    // ìºì‹œ í™•ì¸ (ì¬ë°©ë¬¸ ì¦‰ì‹œ ë¡œë“œ)
    const cacheKey = `${repo}:${depth}:${path}`
    if (!skipCache) {
      const cachedResult = analysisCache.get(cacheKey)
      if (cachedResult) {
        return NextResponse.json({
          ...cachedResult,
          cached: true,
          cache_time: new Date().toISOString(),
        })
      }
    }

    const [owner, repoName] = repo.split('/')

    // 1. ë ˆí¬ì§€í† ë¦¬ íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì ìš©)
    const treeCacheKey = `${repo}:tree`
    let treeData: GitHubTreeResponse = treeCache.get(treeCacheKey) ?? { tree: [] }

    if (treeData.tree.length === 0) {
      const branches = ['main', 'master']

      for (const branch of branches) {
        const treeResponse = await fetch(
          `https://api.github.com/repos/${owner}/${repoName}/git/trees/${branch}?recursive=1`,
          {
            headers: {
              'Authorization': `Bearer ${token}`,
              'Accept': 'application/vnd.github.v3+json',
            },
          }
        )

        if (treeResponse.ok) {
          treeData = await treeResponse.json()
          treeCache.set(treeCacheKey, treeData)
          break
        }
      }
    }

    // 2. ì´ìŠˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì ìš©)
    const issuesCacheKey = `${repo}:issues`
    let issuesData: GitHubIssue[] = (issuesCache.get(issuesCacheKey) as GitHubIssue[]) ?? []

    if (issuesData.length === 0) {
      const issuesResponse = await fetch(
        `https://api.github.com/repos/${owner}/${repoName}/issues?state=open&per_page=50`,
        {
          headers: {
            'Authorization': `Bearer ${token}`,
            'Accept': 'application/vnd.github.v3+json',
          },
        }
      )

      issuesData = issuesResponse.ok ? await issuesResponse.json() : []
      issuesCache.set(issuesCacheKey, issuesData)
    }

    // 3. ë ˆì´ì–´ë³„ íŒŒì¼ ë¶„ë¥˜ + ìƒ˜í”Œë§ ì „ëµ (ëŒ€ê·œëª¨ ë ˆí¬ ìµœì í™”)
    const layerFiles: Record<string, string[]> = {
      ui: [],
      logic: [],
      server: [],
      data: [],
    }

    // ëª¨ë“  ì½”ë“œ íŒŒì¼ í•„í„°ë§ (ìë™ ê²½ë¡œ íƒì§€ ì§€ì›)
    let allCodeFiles = (treeData.tree || []).filter((item: GitHubTreeItem) =>
      item.type === 'blob' &&
      item.path.startsWith(path.replace(/^\//, '')) &&
      (item.path.endsWith('.ts') || item.path.endsWith('.tsx') ||
       item.path.endsWith('.js') || item.path.endsWith('.jsx') ||
       item.path.endsWith('.py'))
    )

    // ìë™ ê²½ë¡œ íƒì§€: ê¸°ë³¸ ê²½ë¡œì— íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ê²½ë¡œ ì‹œë„
    let detectedPath = path
    if (allCodeFiles.length === 0 && path === 'src/') {
      // ì œì™¸í•  ë””ë ‰í† ë¦¬ íŒ¨í„´ (node_modules, ë¹Œë“œ ê²°ê³¼ë¬¼, Git, í…ŒìŠ¤íŠ¸)
      const excludePatterns = [
        'node_modules/',
        'dist/',
        'build/',
        '.next/',
        'out/',
        '.git/',
        'coverage/',
        '__tests__/',
        'test/',
        'tests/',
        '.cache/',
        'public/',
        'static/',
      ]

      // ì¼ë°˜ì ì¸ ì†ŒìŠ¤ ì½”ë“œ ê²½ë¡œ (ìš°ì„ ìˆœìœ„ ìˆœ)
      const commonPaths = [
        'web/src/',      // Monorepo: web app
        'frontend/src/', // Frontend/Backend ë¶„ë¦¬
        'app/src/',      // Mobile app êµ¬ì¡°
        'client/src/',   // Client/Server ë¶„ë¦¬
        'server/src/',   // Server ì½”ë“œ
        'backend/src/',  // Backend ì½”ë“œ
        'packages/',     // Yarn/pnpm workspace
        'apps/',         // Nx/Turborepo
        'src/',          // í‘œì¤€
        'lib/',          // ë¼ì´ë¸ŒëŸ¬ë¦¬
      ]

      const shouldExclude = (path: string): boolean => {
        return excludePatterns.some(pattern => path.includes(pattern))
      }

      for (const tryPath of commonPaths) {
        const files = (treeData.tree || []).filter((item: GitHubTreeItem) =>
          item.type === 'blob' &&
          item.path.startsWith(tryPath) &&
          !shouldExclude(item.path) &&
          (item.path.endsWith('.ts') || item.path.endsWith('.tsx') ||
           item.path.endsWith('.js') || item.path.endsWith('.jsx') ||
           item.path.endsWith('.py'))
        )

        if (files.length > 0) {
          allCodeFiles = files
          detectedPath = tryPath
          console.log(`[Auto Path Detection] Found ${files.length} files in "${tryPath}"`)
          break
        }
      }
    }

    // ë¹ˆ ê²°ê³¼ ê²€ì¦
    if (allCodeFiles.length === 0) {
      return NextResponse.json({
        error: 'ë¶„ì„ ê°€ëŠ¥í•œ ì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
        details: {
          repo,
          searchedPath: path,
          suggestion: 'ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\n' +
            '1. ë ˆí¬ì§€í† ë¦¬ì— TypeScript, JavaScript, Python íŒŒì¼ì´ ìˆëŠ”ì§€\n' +
            '2. íŒŒì¼ì´ ì¼ë°˜ì ì¸ ê²½ë¡œì— ìˆëŠ”ì§€ (ì•„ë˜ ëª©ë¡ ì°¸ì¡°)\n' +
            '3. íŠ¹ì´í•œ ê²½ë¡œì¸ ê²½ìš° URLì— ?path=your/custom/path íŒŒë¼ë¯¸í„° ì¶”ê°€',
          commonPaths: [
            'src/', 'web/src/', 'frontend/src/', 'backend/src/',
            'client/src/', 'server/src/', 'app/src/',
            'packages/', 'apps/', 'lib/'
          ],
          excludedPaths: [
            'node_modules/', 'dist/', 'build/', '.next/',
            '.git/', 'coverage/', 'test/', 'public/'
          ],
          example: `${repo}?path=your/custom/path`
        }
      }, { status: 404 })
    }

    // ìƒ˜í”Œë§ ì „ëµ: ë ˆí¬ í¬ê¸°ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ìƒ˜í”Œë§
    const MAX_FILES = depth === 'full' ? 100 : depth === 'medium' ? 50 : 20
    const shouldSample = allCodeFiles.length > MAX_FILES

    // ì¤‘ìš” íŒŒì¼ ìš°ì„  ì„ íƒ (ì§„ì…ì , API ë¼ìš°íŠ¸, ì£¼ìš” ì»´í¬ë„ŒíŠ¸)
    const priorityPatterns = [
      /page\.(tsx?|jsx?)$/,           // Next.js í˜ì´ì§€
      /route\.(tsx?|jsx?)$/,          // API ë¼ìš°íŠ¸
      /index\.(tsx?|jsx?)$/,          // ì§„ì…ì 
      /layout\.(tsx?|jsx?)$/,         // ë ˆì´ì•„ì›ƒ
      /(use[A-Z].*)\.(tsx?|jsx?)$/,   // ì»¤ìŠ¤í…€ í›…
      /\.service\.(tsx?|jsx?)$/,      // ì„œë¹„ìŠ¤ ë ˆì´ì–´
      /\.store\.(tsx?|jsx?)$/,        // ìƒíƒœ ê´€ë¦¬
    ]

    let codeFiles: GitHubTreeItem[]
    if (shouldSample) {
      // ìš°ì„ ìˆœìœ„ íŒŒì¼ ë¨¼ì €
      const priorityFiles = allCodeFiles.filter((f: GitHubTreeItem) =>
        priorityPatterns.some(p => p.test(f.path))
      )
      // ë‚˜ë¨¸ì§€ íŒŒì¼ ëœë¤ ìƒ˜í”Œë§
      const otherFiles = allCodeFiles.filter((f: GitHubTreeItem) =>
        !priorityPatterns.some(p => p.test(f.path))
      )
      const shuffled = otherFiles.sort(() => Math.random() - 0.5)
      codeFiles = [...priorityFiles, ...shuffled].slice(0, MAX_FILES)
    } else {
      codeFiles = allCodeFiles
    }

    for (const file of codeFiles) {
      const layer = inferLayer(file.path)
      const fileName = file.path.split('/').pop()?.replace(/\.(tsx?|jsx?|py)$/, '') || ''
      if (!layerFiles[layer].includes(fileName)) {
        layerFiles[layer].push(fileName)
      }
    }

    // 4. ë ˆì´ì–´ ì •ë³´ ìƒì„±
    const layers: Layer[] = [
      {
        name: 'ui',
        displayName: 'í™”ë©´ (UI)',
        modules: layerFiles.ui.slice(0, 6),
        description: 'ì‚¬ìš©ìê°€ ë³´ëŠ” í™”ë©´ê³¼ ë²„íŠ¼',
      },
      {
        name: 'logic',
        displayName: 'ì²˜ë¦¬ (Logic)',
        modules: layerFiles.logic.slice(0, 6),
        description: 'ë°ì´í„° ë³€í™˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§',
      },
      {
        name: 'server',
        displayName: 'ì„œë²„ (API)',
        modules: layerFiles.server.slice(0, 6),
        description: 'ì™¸ë¶€ ì„œë²„ì™€ì˜ í†µì‹ ',
      },
      {
        name: 'data',
        displayName: 'ì €ì¥ (Data)',
        modules: layerFiles.data.slice(0, 6),
        description: 'ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒíƒœ ê´€ë¦¬',
      },
    ].filter(layer => layer.modules.length > 0)

    // 5. ì—°ê²° ê´€ê³„ ì¶”ë¡  (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    const connections: Connection[] = []

    if (layerFiles.ui.length > 0 && layerFiles.logic.length > 0) {
      connections.push({
        from: 'ui',
        to: 'logic',
        type: 'call',
        label: 'ì´ë²¤íŠ¸ ì²˜ë¦¬',
      })
    }

    if (layerFiles.logic.length > 0 && layerFiles.server.length > 0) {
      connections.push({
        from: 'logic',
        to: 'server',
        type: 'fetch',
        label: 'API í˜¸ì¶œ',
      })
    }

    if (layerFiles.server.length > 0 && layerFiles.data.length > 0) {
      connections.push({
        from: 'server',
        to: 'data',
        type: 'call',
        label: 'ë°ì´í„° ì €ì¥',
      })
    }

    if (layerFiles.logic.length > 0 && layerFiles.data.length > 0) {
      connections.push({
        from: 'logic',
        to: 'data',
        type: 'call',
        label: 'ìƒíƒœ ê´€ë¦¬',
      })
    }

    // 6. ìœ„í—˜ ì§€ì  ë¶„ì„ + import íŒŒì‹± (depthì— ë”°ë¼) - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
    const riskPoints: RiskPoint[] = []
    const allImports: Array<{ from: string; to: string; imports: string[] }> = []

    if (include_risk && depth !== 'shallow') {
      // ì£¼ìš” íŒŒì¼ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ 5ë°° ì†ë„ í–¥ìƒ)
      const filesToAnalyze = codeFiles.slice(0, depth === 'full' ? 15 : 8)
      const FILE_TIMEOUT = 8000  // íŒŒì¼ë‹¹ 8ì´ˆ íƒ€ì„ì•„ì›ƒ (ë³‘ë ¬ì´ë¯€ë¡œ ì§§ê²Œ)
      const BATCH_SIZE = 5  // ë™ì‹œ ìš”ì²­ ì œí•œ (GitHub API rate limit ê³ ë ¤)

      // ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ì²˜ë¦¬
      for (let i = 0; i < filesToAnalyze.length; i += BATCH_SIZE) {
        const batch = filesToAnalyze.slice(i, i + BATCH_SIZE)

        const batchResults = await Promise.allSettled(
          batch.map(async (file) => {
            const contentResponse = await fetch(
              `https://api.github.com/repos/${owner}/${repoName}/contents/${file.path}`,
              {
                headers: {
                  'Authorization': `Bearer ${token}`,
                  'Accept': 'application/vnd.github.v3+json',
                },
                signal: AbortSignal.timeout(FILE_TIMEOUT),
              }
            )

            if (!contentResponse.ok) return null

            const contentData = await contentResponse.json()
            if (!contentData.content) return null

            const content = Buffer.from(contentData.content, 'base64').toString('utf-8')

            return {
              path: file.path,
              risks: detectRiskPatterns(content, file.path),
              imports: extractImports(content, file.path),
            }
          })
        )

        // ê²°ê³¼ ìˆ˜ì§‘
        for (const result of batchResults) {
          if (result.status === 'fulfilled' && result.value) {
            riskPoints.push(...result.value.risks)
            allImports.push(...result.value.imports)
          }
        }
      }
    }

    // v6.3: ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
    const cycles = detectCircularDependencies(allImports)
    const circularDependencies: CircularDependency[] = cycles.map(cycle => ({
      cycle,
      severity: cycle.length > 3 ? 'error' : 'warning',
      suggestion: 'ì˜ì¡´ì„± ë°©í–¥ ì¬ì„¤ê³„ ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬ ê¶Œì¥',
    }))

    // v6.3: ë¯¸ì‚¬ìš© íŒŒì¼ íƒì§€
    const entryPoints = codeFiles
      .filter((f: GitHubTreeItem) => f.path.includes('page.') || f.path.includes('route.') || f.path.includes('index.'))
      .map((f: GitHubTreeItem) => f.path)
    const unusedFiles = detectUnusedFiles(
      codeFiles.map((f: GitHubTreeItem) => f.path),
      allImports,
      entryPoints
    )

    // v6.3: ì‹¤ì œ import ê¸°ë°˜ connections ìƒì„±
    const importConnections: Connection[] = []
    const addedConnections = new Set<string>()

    for (const imp of allImports.slice(0, 20)) {
      // node_modulesëŠ” ì œì™¸
      if (imp.to.includes('node_modules')) continue

      const fromLayer = inferLayer(imp.from)
      const toLayer = inferLayer(imp.to)
      const connKey = `${fromLayer}-${toLayer}`

      if (!addedConnections.has(connKey) && fromLayer !== toLayer) {
        addedConnections.add(connKey)
        importConnections.push({
          from: fromLayer,
          to: toLayer,
          type: 'import',
          label: `${imp.imports.slice(0, 2).join(', ')}${imp.imports.length > 2 ? '...' : ''}`,
          imports: imp.imports,
        })
      }
    }

    // ê¸°ì¡´ íœ´ë¦¬ìŠ¤í‹± connectionsì— import ê¸°ë°˜ ì¶”ê°€
    const finalConnections = [...connections, ...importConnections.filter(
      ic => !connections.some(c => c.from === ic.from && c.to === ic.to)
    )]

    // 7. ì´ìŠˆ ì •ë³´ ë³€í™˜ ë° ë ˆì´ì–´ ì—°ê²°
    const issues = issuesData.slice(0, 10).map((issue: GitHubIssue) => {
      let relatedLayer: string | undefined

      const titleLower = issue.title.toLowerCase()
      const bodyLower = (issue.body || '').toLowerCase()

      if (titleLower.includes('ui') || titleLower.includes('í™”ë©´') || bodyLower.includes('component')) {
        relatedLayer = 'ui'
      } else if (titleLower.includes('api') || titleLower.includes('ì„œë²„')) {
        relatedLayer = 'server'
      } else if (titleLower.includes('db') || titleLower.includes('ë°ì´í„°')) {
        relatedLayer = 'data'
      }

      return {
        number: issue.number,
        title: issue.title,
        labels: issue.labels.map((l: { name: string }) => l.name),
        related_layer: relatedLayer,
      }
    })

    // 8. Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (ë°ì´í„° íë¦„ë„) - Issue #6 ê°œì„ 
    // ë ˆì´ì–´ë³„ ìƒ‰ìƒ ì •ì˜
    const LAYER_COLORS: Record<string, { fill: string; stroke: string; text: string }> = {
      ui: { fill: '#dbeafe', stroke: '#3b82f6', text: '#1e40af' },
      logic: { fill: '#dcfce7', stroke: '#22c55e', text: '#166534' },
      server: { fill: '#ffedd5', stroke: '#f97316', text: '#9a3412' },
      data: { fill: '#e0e7ff', stroke: '#6366f1', text: '#3730a3' },
    }

    // ìˆœí™˜ ì˜ì¡´ì„±ì— í¬í•¨ëœ íŒŒì¼ ì¶”ì¶œ
    const circularFiles = new Set<string>()
    for (const cd of circularDependencies) {
      cd.cycle.forEach(file => {
        const fileName = file.split('/').pop()?.replace(/\.(tsx?|jsx?)$/, '') || ''
        circularFiles.add(fileName)
      })
    }

    const mermaidLines = [
      'flowchart TB',
      '  subgraph User["ğŸ‘¤ ì‚¬ìš©ì"]',
      '    action["í–‰ë™/ì…ë ¥"]',
      '  end',
    ]

    // ë ˆì´ì–´ ì„œë¸Œê·¸ë˜í”„ (ìƒ‰ìƒ ì ìš©)
    for (const layer of layers) {
      const colors = LAYER_COLORS[layer.name] || LAYER_COLORS.logic

      mermaidLines.push(`  subgraph ${layer.name}["${layer.displayName}"]`)
      mermaidLines.push(`    style ${layer.name} fill:${colors.fill},stroke:${colors.stroke}`)

      for (const mod of layer.modules.slice(0, 4)) {
        const safeMod = mod.replace(/[^a-zA-Z0-9]/g, '_')
        const nodeId = `${layer.name}_${safeMod}`
        const isCircular = circularFiles.has(mod)
        const icon = isCircular ? 'ğŸ”´ ' : ''

        mermaidLines.push(`    ${nodeId}["${icon}${mod}"]`)

        // ìˆœí™˜ ì˜ì¡´ì„± ë…¸ë“œ ìŠ¤íƒ€ì¼
        if (isCircular) {
          mermaidLines.push(`    style ${nodeId} fill:#fef2f2,stroke:#dc2626,stroke-width:3px`)
        }
      }

      if (layer.modules.length > 4) {
        mermaidLines.push(`    ${layer.name}_more["...ì™¸ ${layer.modules.length - 4}ê°œ"]`)
      }

      mermaidLines.push('  end')
    }

    // ì—°ê²°ì„  (íƒ€ì…ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼)
    mermaidLines.push('  action --> ui')

    for (const conn of connections) {
      const label = conn.label || ''
      // íƒ€ì…ì— ë”°ë¥¸ ì—°ê²°ì„  ìŠ¤íƒ€ì¼
      if (conn.type === 'import') {
        mermaidLines.push(`  ${conn.from} -.->|"${label}"| ${conn.to}`)
      } else {
        mermaidLines.push(`  ${conn.from} -->|"${label}"| ${conn.to}`)
      }
    }

    // ìˆœí™˜ ì˜ì¡´ì„± ì—°ê²°ì„  (ë¹¨ê°„ ì ì„ )
    for (const cd of circularDependencies.slice(0, 3)) {
      if (cd.cycle.length >= 2) {
        const from = inferLayer(cd.cycle[0])
        const to = inferLayer(cd.cycle[1])
        if (from !== to) {
          mermaidLines.push(`  ${from} <-.->|"âš ï¸ ìˆœí™˜"| ${to}`)
        }
      }
    }

    // ë ˆì´ì–´ë³„ ìŠ¤íƒ€ì¼ í´ë˜ìŠ¤ ì •ì˜
    mermaidLines.push(`  classDef ui fill:${LAYER_COLORS.ui.fill},stroke:${LAYER_COLORS.ui.stroke},color:${LAYER_COLORS.ui.text}`)
    mermaidLines.push(`  classDef logic fill:${LAYER_COLORS.logic.fill},stroke:${LAYER_COLORS.logic.stroke},color:${LAYER_COLORS.logic.text}`)
    mermaidLines.push(`  classDef server fill:${LAYER_COLORS.server.fill},stroke:${LAYER_COLORS.server.stroke},color:${LAYER_COLORS.server.text}`)
    mermaidLines.push(`  classDef data fill:${LAYER_COLORS.data.fill},stroke:${LAYER_COLORS.data.stroke},color:${LAYER_COLORS.data.text}`)
    mermaidLines.push('  classDef hasIssue fill:#fef2f2,stroke:#dc2626,stroke-dasharray:5 5')
    mermaidLines.push('  classDef circular fill:#fef2f2,stroke:#dc2626,stroke-width:3px')

    // ì´ìŠˆ ìˆëŠ” ë ˆì´ì–´ì— ìŠ¤íƒ€ì¼ ì ìš©
    for (const issue of issues) {
      if (issue.related_layer) {
        mermaidLines.push(`  class ${issue.related_layer} hasIssue`)
      }
    }

    // ë ˆì´ì–´ í´ë˜ìŠ¤ ì ìš©
    for (const layer of layers) {
      mermaidLines.push(`  class ${layer.name} ${layer.name}`)
    }

    // v6.3: ë¶„ì„ í†µê³„ (ìƒ˜í”Œë§ ì •ë³´ í¬í•¨)
    const stats: AnalysisStats = {
      totalFiles: allCodeFiles.length,  // ì „ì²´ íŒŒì¼ ìˆ˜
      analyzedFiles: codeFiles.length,  // ì‹¤ì œ ë¶„ì„í•œ íŒŒì¼ ìˆ˜
      totalDependencies: allImports.length,
      circularCount: circularDependencies.length,
      unusedCount: unusedFiles.length,
    }

    const response: AnalyzeResponse = {
      repo,
      level: 'overview',
      analysis_method: shouldSample ? 'sampling-import-parsing' : 'import-parsing',
      data_flow: {
        entry_points: entryPoints.slice(0, 5),
        layers,
        connections: finalConnections,
      },
      circular_dependencies: circularDependencies,
      unused_files: unusedFiles.slice(0, 10),
      risk_points: riskPoints.slice(0, 10),
      issues,
      mermaid_code: mermaidLines.join('\n'),
      stats,
      summary: `${repo}: ${layers.length}ê°œ ë ˆì´ì–´, ${allImports.length}ê°œ ì˜ì¡´ì„±, ${circularDependencies.length}ê°œ ìˆœí™˜, ${riskPoints.length}ê°œ ìœ„í—˜ ì§€ì `,
      // ìë™ ê²½ë¡œ íƒì§€ ì •ë³´
      ...(detectedPath !== path && { detectedPath, requestedPath: path }),
    }

    // ê²°ê³¼ ìºì‹± (ì¬ë°©ë¬¸ ì¦‰ì‹œ ë¡œë“œ)
    analysisCache.set(cacheKey, response)

    return NextResponse.json(response)

  } catch (error) {
    console.error('Logic flow analyze error:', error)
    return NextResponse.json({ error: 'ì½”ë“œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' }, { status: 500 })
  }
}

// GET í•¸ë“¤ëŸ¬ (SWR ìºì‹± ì§€ì›)
export async function GET(request: NextRequest) {
  const searchParams = request.nextUrl.searchParams
  const params = {
    repo: searchParams.get('repo') ?? undefined,
    path: searchParams.get('path') ?? undefined,
    depth: searchParams.get('depth') ?? undefined,
    include_risk: searchParams.get('include_risk') === 'true',
    skipCache: searchParams.get('skipCache') === 'true',
  }

  return analyzeCodebase(request, params)
}

// POST í•¸ë“¤ëŸ¬ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
export async function POST(request: NextRequest) {
  try {
    // ì•ˆì „í•œ JSON íŒŒì‹± (ë¹ˆ body ì²˜ë¦¬)
    let body: { repo?: string; path?: string; depth?: string; include_risk?: boolean; skipCache?: boolean }
    try {
      const text = await request.text()
      if (!text || text.trim() === '') {
        return NextResponse.json({ error: 'Request body is required' }, { status: 400 })
      }
      body = JSON.parse(text)
    } catch {
      return NextResponse.json({ error: 'Invalid JSON in request body' }, { status: 400 })
    }

    return analyzeCodebase(request, body)
  } catch (error) {
    console.error('Logic flow analyze error:', error)
    return NextResponse.json({ error: 'ì½”ë“œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' }, { status: 500 })
  }
}
