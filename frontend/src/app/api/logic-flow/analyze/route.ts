/**
 * Logic Flow API - Code Analysis (Level 1-A: Big Picture)
 * PRD v6.3 Section 1.2: ë¹„ê°œë°œì ì¹œí™”ì  ì‹œê°í™” ì „ëµ
 *
 * v6.3 ì—…ë°ì´íŠ¸:
 * - ì‹¤ì œ import ë¬¸ íŒŒì‹±ìœ¼ë¡œ ì˜ì¡´ì„± ì¶”ì¶œ
 * - ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
 * - ë¯¸ì‚¬ìš© íŒŒì¼ íƒì§€
 * - ë¶„ì„ í†µê³„ ì¶”ê°€
 */

import { NextRequest, NextResponse } from 'next/server'
import { getGitHubTokenFromSession } from '@/lib/auth'

interface Layer {
  name: string
  displayName: string
  modules: string[]
  description: string
}

interface Connection {
  from: string
  to: string
  type: 'call' | 'fetch' | 'import' | 'event'
  label?: string
  imports?: string[]  // v6.3: ì‹¤ì œ import í•­ëª©
}

interface RiskPoint {
  location: string
  function: string
  risk: 'high' | 'medium' | 'low'
  reason: string
  suggestion: string
}

// v6.3: ìˆœí™˜ ì˜ì¡´ì„±
interface CircularDependency {
  cycle: string[]
  severity: 'warning' | 'error'
  suggestion: string
}

// v6.3: ë¶„ì„ í†µê³„
interface AnalysisStats {
  totalFiles: number
  analyzedFiles: number
  totalDependencies: number
  circularCount: number
  unusedCount: number
}

interface AnalyzeResponse {
  repo: string
  level: 'overview'
  analysis_method: 'import-parsing'  // v6.3: ë¶„ì„ ë°©ë²• í‘œì‹œ
  data_flow: {
    entry_points: string[]
    layers: Layer[]
    connections: Connection[]
  }
  circular_dependencies: CircularDependency[]  // v6.3
  unused_files: string[]  // v6.3
  risk_points: RiskPoint[]
  issues: Array<{
    number: number
    title: string
    labels: string[]
    related_layer?: string
  }>
  mermaid_code: string
  stats: AnalysisStats  // v6.3
  summary: string
}

// íŒŒì¼ ê²½ë¡œì—ì„œ ë ˆì´ì–´ ì¶”ë¡ 
function inferLayer(path: string): string {
  const lowerPath = path.toLowerCase()

  // UI ë ˆì´ì–´
  if (lowerPath.includes('component') || lowerPath.includes('page') ||
      lowerPath.includes('view') || lowerPath.includes('ui') ||
      lowerPath.match(/\.(tsx|jsx)$/)) {
    return 'ui'
  }

  // API/Server ë ˆì´ì–´
  if (lowerPath.includes('api') || lowerPath.includes('route') ||
      lowerPath.includes('server') || lowerPath.includes('endpoint')) {
    return 'server'
  }

  // Data ë ˆì´ì–´
  if (lowerPath.includes('model') || lowerPath.includes('schema') ||
      lowerPath.includes('database') || lowerPath.includes('db') ||
      lowerPath.includes('store') || lowerPath.includes('state')) {
    return 'data'
  }

  // Logic ë ˆì´ì–´ (ê¸°ë³¸)
  if (lowerPath.includes('service') || lowerPath.includes('util') ||
      lowerPath.includes('lib') || lowerPath.includes('helper') ||
      lowerPath.includes('hook')) {
    return 'logic'
  }

  return 'logic' // ê¸°ë³¸ê°’
}

// ì½”ë“œì—ì„œ ìœ„í—˜ íŒ¨í„´ ê°ì§€
function detectRiskPatterns(content: string, path: string): RiskPoint[] {
  const risks: RiskPoint[] = []
  const lines = content.split('\n')

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i]
    const lineNum = i + 1

    // íŒ¨í„´ 1: try-catch ì—†ëŠ” fetch/API í˜¸ì¶œ
    if ((line.includes('fetch(') || line.includes('axios') || line.includes('.get(') || line.includes('.post(')) &&
        !lines.slice(Math.max(0, i - 5), i).some(l => l.includes('try'))) {
      // ë‹¤ìŒ 5ì¤„ ì•ˆì— catchê°€ ìˆëŠ”ì§€ í™•ì¸
      const hasNearCatch = lines.slice(i, Math.min(lines.length, i + 10)).some(l => l.includes('catch'))
      if (!hasNearCatch) {
        risks.push({
          location: `${path}:${lineNum}`,
          function: extractFunctionName(lines, i),
          risk: 'high',
          reason: 'API í˜¸ì¶œ í›„ ì—ëŸ¬ ì²˜ë¦¬ ì—†ìŒ',
          suggestion: 'try-catch ì¶”ê°€ ë˜ëŠ” .catch() í•¸ë“¤ëŸ¬ ì¶”ê°€',
        })
      }
    }

    // íŒ¨í„´ 2: null/undefined ì²´í¬ ì—†ì´ í”„ë¡œí¼í‹° ì ‘ê·¼
    const unsafeAccess = line.match(/(\w+)\.(\w+)\.(\w+)/)
    if (unsafeAccess && !line.includes('?.') && !line.includes('&&') &&
        !line.includes('if') && !line.includes('||')) {
      risks.push({
        location: `${path}:${lineNum}`,
        function: extractFunctionName(lines, i),
        risk: 'medium',
        reason: 'ê¹Šì€ í”„ë¡œí¼í‹° ì ‘ê·¼ ì‹œ null ì²´í¬ ì—†ìŒ',
        suggestion: 'ì˜µì…”ë„ ì²´ì´ë‹(?.) ì‚¬ìš© ê¶Œì¥',
      })
    }

    // íŒ¨í„´ 3: console.log ë‚¨ì•„ìˆìŒ (í”„ë¡œë•ì…˜ ì½”ë“œ)
    if (line.includes('console.log') && !path.includes('test') && !path.includes('spec')) {
      risks.push({
        location: `${path}:${lineNum}`,
        function: extractFunctionName(lines, i),
        risk: 'low',
        reason: 'ë””ë²„ê·¸ ë¡œê·¸ê°€ í”„ë¡œë•ì…˜ ì½”ë“œì— ë‚¨ì•„ìˆìŒ',
        suggestion: 'ë°°í¬ ì „ console.log ì œê±° í•„ìš”',
      })
    }
  }

  return risks.slice(0, 5) // íŒŒì¼ë‹¹ ìµœëŒ€ 5ê°œ
}

function extractFunctionName(lines: string[], currentIndex: number): string {
  // ìœ„ë¡œ ì˜¬ë¼ê°€ë©´ì„œ í•¨ìˆ˜ ì •ì˜ ì°¾ê¸°
  for (let i = currentIndex; i >= Math.max(0, currentIndex - 20); i--) {
    const line = lines[i]
    const funcMatch = line.match(/(?:function|const|let|var)\s+(\w+)|(\w+)\s*[=:]\s*(?:async\s*)?\(/)
    if (funcMatch) {
      return funcMatch[1] || funcMatch[2] || 'anonymous'
    }
  }
  return 'anonymous'
}

// v6.3: ì½”ë“œì—ì„œ import ë¬¸ ì¶”ì¶œ
function extractImports(content: string, filePath: string): Array<{ from: string; to: string; imports: string[] }> {
  const imports: Array<{ from: string; to: string; imports: string[] }> = []
  const lines = content.split('\n')

  for (const line of lines) {
    // import { x, y } from './module'
    const namedImportMatch = line.match(/import\s*\{([^}]+)\}\s*from\s*['"]([^'"]+)['"]/)
    if (namedImportMatch) {
      const importedItems = namedImportMatch[1].split(',').map(s => s.trim().split(' as ')[0])
      const modulePath = namedImportMatch[2]
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, modulePath),
        imports: importedItems,
      })
      continue
    }

    // import x from './module'
    const defaultImportMatch = line.match(/import\s+(\w+)\s+from\s*['"]([^'"]+)['"]/)
    if (defaultImportMatch) {
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, defaultImportMatch[2]),
        imports: [defaultImportMatch[1]],
      })
      continue
    }

    // import * as x from './module'
    const namespaceImportMatch = line.match(/import\s*\*\s*as\s+(\w+)\s+from\s*['"]([^'"]+)['"]/)
    if (namespaceImportMatch) {
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, namespaceImportMatch[2]),
        imports: [`* as ${namespaceImportMatch[1]}`],
      })
      continue
    }

    // import './module' (side effect)
    const sideEffectMatch = line.match(/import\s*['"]([^'"]+)['"]/)
    if (sideEffectMatch && !line.includes('from')) {
      imports.push({
        from: filePath,
        to: resolveImportPath(filePath, sideEffectMatch[1]),
        imports: ['(side effect)'],
      })
    }
  }

  return imports
}

// import ê²½ë¡œ í•´ì„
function resolveImportPath(fromPath: string, importPath: string): string {
  // ìƒëŒ€ ê²½ë¡œê°€ ì•„ë‹Œ ê²½ìš° (íŒ¨í‚¤ì§€ import)
  if (!importPath.startsWith('.') && !importPath.startsWith('@/')) {
    return `node_modules/${importPath}`
  }

  // @/ alias ì²˜ë¦¬
  if (importPath.startsWith('@/')) {
    return importPath.replace('@/', 'src/')
  }

  // ìƒëŒ€ ê²½ë¡œ í•´ì„ (ê°„ë‹¨í•œ ë²„ì „)
  const fromDir = fromPath.split('/').slice(0, -1).join('/')
  const parts = importPath.split('/')
  let result = fromDir.split('/')

  for (const part of parts) {
    if (part === '..') {
      result.pop()
    } else if (part !== '.') {
      result.push(part)
    }
  }

  return result.join('/')
}

// v6.3: ìˆœí™˜ ì˜ì¡´ì„± íƒì§€ (DFS)
function detectCircularDependencies(
  imports: Array<{ from: string; to: string }>
): string[][] {
  const graph = new Map<string, string[]>()

  // ê·¸ë˜í”„ êµ¬ì¶•
  for (const imp of imports) {
    if (!graph.has(imp.from)) {
      graph.set(imp.from, [])
    }
    graph.get(imp.from)!.push(imp.to)
  }

  const cycles: string[][] = []
  const visited = new Set<string>()
  const recursionStack = new Set<string>()

  function dfs(node: string, path: string[]): void {
    if (recursionStack.has(node)) {
      // ìˆœí™˜ ë°œê²¬
      const cycleStart = path.indexOf(node)
      if (cycleStart !== -1) {
        cycles.push([...path.slice(cycleStart), node])
      }
      return
    }

    if (visited.has(node)) {
      return
    }

    visited.add(node)
    recursionStack.add(node)

    const neighbors = graph.get(node) || []
    for (const neighbor of neighbors) {
      dfs(neighbor, [...path, node])
    }

    recursionStack.delete(node)
  }

  for (const node of graph.keys()) {
    dfs(node, [])
  }

  return cycles
}

// v6.3: ë¯¸ì‚¬ìš© íŒŒì¼ íƒì§€
function detectUnusedFiles(
  allFiles: string[],
  imports: Array<{ from: string; to: string }>,
  entryPoints: string[]
): string[] {
  const importedFiles = new Set<string>()

  // ëª¨ë“  importëœ íŒŒì¼ ìˆ˜ì§‘
  for (const imp of imports) {
    importedFiles.add(imp.to)
  }

  // ì§„ì…ì  ì¶”ê°€
  for (const entry of entryPoints) {
    importedFiles.add(entry)
  }

  // importë˜ì§€ ì•Šì€ íŒŒì¼ ì°¾ê¸°
  return allFiles.filter(file => {
    const normalizedFile = file.replace(/\.(tsx?|jsx?)$/, '')
    return !importedFiles.has(normalizedFile) &&
           !importedFiles.has(file) &&
           !file.includes('test') &&
           !file.includes('spec') &&
           !file.includes('.d.ts')
  })
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { repo, path = 'src/', depth = 'medium', include_risk = true } = body

    if (!repo) {
      return NextResponse.json({ error: 'repo parameter required' }, { status: 400 })
    }

    // ì¸ì¦ í™•ì¸
    const { token } = await getGitHubTokenFromSession()

    if (!token) {
      return NextResponse.json({ error: 'GitHub ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.' }, { status: 401 })
    }

    const [owner, repoName] = repo.split('/')

    // 1. ë ˆí¬ì§€í† ë¦¬ íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
    let treeData: any = { tree: [] }
    const branches = ['main', 'master']

    for (const branch of branches) {
      const treeResponse = await fetch(
        `https://api.github.com/repos/${owner}/${repoName}/git/trees/${branch}?recursive=1`,
        {
          headers: {
            'Authorization': `Bearer ${token}`,
            'Accept': 'application/vnd.github.v3+json',
          },
        }
      )

      if (treeResponse.ok) {
        treeData = await treeResponse.json()
        break
      }
    }

    // 2. ì´ìŠˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    const issuesResponse = await fetch(
      `https://api.github.com/repos/${owner}/${repoName}/issues?state=open&per_page=50`,
      {
        headers: {
          'Authorization': `Bearer ${token}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    )

    const issuesData = issuesResponse.ok ? await issuesResponse.json() : []

    // 3. ë ˆì´ì–´ë³„ íŒŒì¼ ë¶„ë¥˜
    const layerFiles: Record<string, string[]> = {
      ui: [],
      logic: [],
      server: [],
      data: [],
    }

    const codeFiles = (treeData.tree || []).filter((item: any) =>
      item.type === 'blob' &&
      item.path.startsWith(path.replace(/^\//, '')) &&
      (item.path.endsWith('.ts') || item.path.endsWith('.tsx') ||
       item.path.endsWith('.js') || item.path.endsWith('.jsx') ||
       item.path.endsWith('.py'))
    )

    for (const file of codeFiles) {
      const layer = inferLayer(file.path)
      const fileName = file.path.split('/').pop()?.replace(/\.(tsx?|jsx?|py)$/, '') || ''
      if (!layerFiles[layer].includes(fileName)) {
        layerFiles[layer].push(fileName)
      }
    }

    // 4. ë ˆì´ì–´ ì •ë³´ ìƒì„±
    const layers: Layer[] = [
      {
        name: 'ui',
        displayName: 'í™”ë©´ (UI)',
        modules: layerFiles.ui.slice(0, 6),
        description: 'ì‚¬ìš©ìê°€ ë³´ëŠ” í™”ë©´ê³¼ ë²„íŠ¼',
      },
      {
        name: 'logic',
        displayName: 'ì²˜ë¦¬ (Logic)',
        modules: layerFiles.logic.slice(0, 6),
        description: 'ë°ì´í„° ë³€í™˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§',
      },
      {
        name: 'server',
        displayName: 'ì„œë²„ (API)',
        modules: layerFiles.server.slice(0, 6),
        description: 'ì™¸ë¶€ ì„œë²„ì™€ì˜ í†µì‹ ',
      },
      {
        name: 'data',
        displayName: 'ì €ì¥ (Data)',
        modules: layerFiles.data.slice(0, 6),
        description: 'ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒíƒœ ê´€ë¦¬',
      },
    ].filter(layer => layer.modules.length > 0)

    // 5. ì—°ê²° ê´€ê³„ ì¶”ë¡  (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    const connections: Connection[] = []

    if (layerFiles.ui.length > 0 && layerFiles.logic.length > 0) {
      connections.push({
        from: 'ui',
        to: 'logic',
        type: 'call',
        label: 'ì´ë²¤íŠ¸ ì²˜ë¦¬',
      })
    }

    if (layerFiles.logic.length > 0 && layerFiles.server.length > 0) {
      connections.push({
        from: 'logic',
        to: 'server',
        type: 'fetch',
        label: 'API í˜¸ì¶œ',
      })
    }

    if (layerFiles.server.length > 0 && layerFiles.data.length > 0) {
      connections.push({
        from: 'server',
        to: 'data',
        type: 'call',
        label: 'ë°ì´í„° ì €ì¥',
      })
    }

    if (layerFiles.logic.length > 0 && layerFiles.data.length > 0) {
      connections.push({
        from: 'logic',
        to: 'data',
        type: 'call',
        label: 'ìƒíƒœ ê´€ë¦¬',
      })
    }

    // 6. ìœ„í—˜ ì§€ì  ë¶„ì„ + import íŒŒì‹± (depthì— ë”°ë¼)
    let riskPoints: RiskPoint[] = []
    const allImports: Array<{ from: string; to: string; imports: string[] }> = []

    if (include_risk && depth !== 'shallow') {
      // ì£¼ìš” íŒŒì¼ ëª‡ ê°œë§Œ ë¶„ì„ (API ìš”ì²­ ì œí•œ)
      const filesToAnalyze = codeFiles.slice(0, depth === 'full' ? 15 : 8)

      for (const file of filesToAnalyze) {
        try {
          const contentResponse = await fetch(
            `https://api.github.com/repos/${owner}/${repoName}/contents/${file.path}`,
            {
              headers: {
                'Authorization': `Bearer ${token}`,
                'Accept': 'application/vnd.github.v3+json',
              },
            }
          )

          if (contentResponse.ok) {
            const contentData = await contentResponse.json()
            if (contentData.content) {
              const content = Buffer.from(contentData.content, 'base64').toString('utf-8')

              // ìœ„í—˜ íŒ¨í„´ ë¶„ì„
              const fileRisks = detectRiskPatterns(content, file.path)
              riskPoints.push(...fileRisks)

              // v6.3: import ë¬¸ ì¶”ì¶œ
              const fileImports = extractImports(content, file.path)
              allImports.push(...fileImports)
            }
          }
        } catch (e) {
          // ê°œë³„ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
        }
      }
    }

    // v6.3: ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
    const cycles = detectCircularDependencies(allImports)
    const circularDependencies: CircularDependency[] = cycles.map(cycle => ({
      cycle,
      severity: cycle.length > 3 ? 'error' : 'warning',
      suggestion: 'ì˜ì¡´ì„± ë°©í–¥ ì¬ì„¤ê³„ ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬ ê¶Œì¥',
    }))

    // v6.3: ë¯¸ì‚¬ìš© íŒŒì¼ íƒì§€
    const entryPoints = codeFiles
      .filter((f: any) => f.path.includes('page.') || f.path.includes('route.') || f.path.includes('index.'))
      .map((f: any) => f.path)
    const unusedFiles = detectUnusedFiles(
      codeFiles.map((f: any) => f.path),
      allImports,
      entryPoints
    )

    // v6.3: ì‹¤ì œ import ê¸°ë°˜ connections ìƒì„±
    const importConnections: Connection[] = []
    const addedConnections = new Set<string>()

    for (const imp of allImports.slice(0, 20)) {
      // node_modulesëŠ” ì œì™¸
      if (imp.to.includes('node_modules')) continue

      const fromLayer = inferLayer(imp.from)
      const toLayer = inferLayer(imp.to)
      const connKey = `${fromLayer}-${toLayer}`

      if (!addedConnections.has(connKey) && fromLayer !== toLayer) {
        addedConnections.add(connKey)
        importConnections.push({
          from: fromLayer,
          to: toLayer,
          type: 'import',
          label: `${imp.imports.slice(0, 2).join(', ')}${imp.imports.length > 2 ? '...' : ''}`,
          imports: imp.imports,
        })
      }
    }

    // ê¸°ì¡´ íœ´ë¦¬ìŠ¤í‹± connectionsì— import ê¸°ë°˜ ì¶”ê°€
    const finalConnections = [...connections, ...importConnections.filter(
      ic => !connections.some(c => c.from === ic.from && c.to === ic.to)
    )]

    // 7. ì´ìŠˆ ì •ë³´ ë³€í™˜ ë° ë ˆì´ì–´ ì—°ê²°
    const issues = issuesData.slice(0, 10).map((issue: any) => {
      let relatedLayer: string | undefined

      const titleLower = issue.title.toLowerCase()
      const bodyLower = (issue.body || '').toLowerCase()

      if (titleLower.includes('ui') || titleLower.includes('í™”ë©´') || bodyLower.includes('component')) {
        relatedLayer = 'ui'
      } else if (titleLower.includes('api') || titleLower.includes('ì„œë²„')) {
        relatedLayer = 'server'
      } else if (titleLower.includes('db') || titleLower.includes('ë°ì´í„°')) {
        relatedLayer = 'data'
      }

      return {
        number: issue.number,
        title: issue.title,
        labels: issue.labels.map((l: any) => l.name),
        related_layer: relatedLayer,
      }
    })

    // 8. Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (ë°ì´í„° íë¦„ë„) - Issue #6 ê°œì„ 
    // ë ˆì´ì–´ë³„ ìƒ‰ìƒ ì •ì˜
    const LAYER_COLORS: Record<string, { fill: string; stroke: string; text: string }> = {
      ui: { fill: '#dbeafe', stroke: '#3b82f6', text: '#1e40af' },
      logic: { fill: '#dcfce7', stroke: '#22c55e', text: '#166534' },
      server: { fill: '#ffedd5', stroke: '#f97316', text: '#9a3412' },
      data: { fill: '#e0e7ff', stroke: '#6366f1', text: '#3730a3' },
    }

    // ìˆœí™˜ ì˜ì¡´ì„±ì— í¬í•¨ëœ íŒŒì¼ ì¶”ì¶œ
    const circularFiles = new Set<string>()
    for (const cd of circularDependencies) {
      cd.cycle.forEach(file => {
        const fileName = file.split('/').pop()?.replace(/\.(tsx?|jsx?)$/, '') || ''
        circularFiles.add(fileName)
      })
    }

    const mermaidLines = [
      'flowchart TB',
      '  subgraph User["ğŸ‘¤ ì‚¬ìš©ì"]',
      '    action["í–‰ë™/ì…ë ¥"]',
      '  end',
    ]

    // ë ˆì´ì–´ ì„œë¸Œê·¸ë˜í”„ (ìƒ‰ìƒ ì ìš©)
    for (const layer of layers) {
      const hasIssue = issues.some((i: any) => i.related_layer === layer.name)
      const colors = LAYER_COLORS[layer.name] || LAYER_COLORS.logic

      mermaidLines.push(`  subgraph ${layer.name}["${layer.displayName}"]`)
      mermaidLines.push(`    style ${layer.name} fill:${colors.fill},stroke:${colors.stroke}`)

      for (const mod of layer.modules.slice(0, 4)) {
        const safeMod = mod.replace(/[^a-zA-Z0-9]/g, '_')
        const nodeId = `${layer.name}_${safeMod}`
        const isCircular = circularFiles.has(mod)
        const icon = isCircular ? 'ğŸ”´ ' : ''

        mermaidLines.push(`    ${nodeId}["${icon}${mod}"]`)

        // ìˆœí™˜ ì˜ì¡´ì„± ë…¸ë“œ ìŠ¤íƒ€ì¼
        if (isCircular) {
          mermaidLines.push(`    style ${nodeId} fill:#fef2f2,stroke:#dc2626,stroke-width:3px`)
        }
      }

      if (layer.modules.length > 4) {
        mermaidLines.push(`    ${layer.name}_more["...ì™¸ ${layer.modules.length - 4}ê°œ"]`)
      }

      mermaidLines.push('  end')
    }

    // ì—°ê²°ì„  (íƒ€ì…ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼)
    mermaidLines.push('  action --> ui')

    for (const conn of connections) {
      const label = conn.label || ''
      // íƒ€ì…ì— ë”°ë¥¸ ì—°ê²°ì„  ìŠ¤íƒ€ì¼
      if (conn.type === 'import') {
        mermaidLines.push(`  ${conn.from} -.->|"${label}"| ${conn.to}`)
      } else {
        mermaidLines.push(`  ${conn.from} -->|"${label}"| ${conn.to}`)
      }
    }

    // ìˆœí™˜ ì˜ì¡´ì„± ì—°ê²°ì„  (ë¹¨ê°„ ì ì„ )
    for (const cd of circularDependencies.slice(0, 3)) {
      if (cd.cycle.length >= 2) {
        const from = inferLayer(cd.cycle[0])
        const to = inferLayer(cd.cycle[1])
        if (from !== to) {
          mermaidLines.push(`  ${from} <-.->|"âš ï¸ ìˆœí™˜"| ${to}`)
        }
      }
    }

    // ë ˆì´ì–´ë³„ ìŠ¤íƒ€ì¼ í´ë˜ìŠ¤ ì •ì˜
    mermaidLines.push(`  classDef ui fill:${LAYER_COLORS.ui.fill},stroke:${LAYER_COLORS.ui.stroke},color:${LAYER_COLORS.ui.text}`)
    mermaidLines.push(`  classDef logic fill:${LAYER_COLORS.logic.fill},stroke:${LAYER_COLORS.logic.stroke},color:${LAYER_COLORS.logic.text}`)
    mermaidLines.push(`  classDef server fill:${LAYER_COLORS.server.fill},stroke:${LAYER_COLORS.server.stroke},color:${LAYER_COLORS.server.text}`)
    mermaidLines.push(`  classDef data fill:${LAYER_COLORS.data.fill},stroke:${LAYER_COLORS.data.stroke},color:${LAYER_COLORS.data.text}`)
    mermaidLines.push('  classDef hasIssue fill:#fef2f2,stroke:#dc2626,stroke-dasharray:5 5')
    mermaidLines.push('  classDef circular fill:#fef2f2,stroke:#dc2626,stroke-width:3px')

    // ì´ìŠˆ ìˆëŠ” ë ˆì´ì–´ì— ìŠ¤íƒ€ì¼ ì ìš©
    for (const issue of issues) {
      if (issue.related_layer) {
        mermaidLines.push(`  class ${issue.related_layer} hasIssue`)
      }
    }

    // ë ˆì´ì–´ í´ë˜ìŠ¤ ì ìš©
    for (const layer of layers) {
      mermaidLines.push(`  class ${layer.name} ${layer.name}`)
    }

    // v6.3: ë¶„ì„ í†µê³„
    const stats: AnalysisStats = {
      totalFiles: codeFiles.length,
      analyzedFiles: depth === 'shallow' ? 0 : (depth === 'full' ? 15 : 8),
      totalDependencies: allImports.length,
      circularCount: circularDependencies.length,
      unusedCount: unusedFiles.length,
    }

    const response: AnalyzeResponse = {
      repo,
      level: 'overview',
      analysis_method: 'import-parsing',
      data_flow: {
        entry_points: entryPoints.slice(0, 5),
        layers,
        connections: finalConnections,
      },
      circular_dependencies: circularDependencies,
      unused_files: unusedFiles.slice(0, 10),
      risk_points: riskPoints.slice(0, 10),
      issues,
      mermaid_code: mermaidLines.join('\n'),
      stats,
      summary: `${repo}: ${layers.length}ê°œ ë ˆì´ì–´, ${allImports.length}ê°œ ì˜ì¡´ì„±, ${circularDependencies.length}ê°œ ìˆœí™˜, ${riskPoints.length}ê°œ ìœ„í—˜ ì§€ì `,
    }

    return NextResponse.json(response)

  } catch (error) {
    console.error('Logic flow analyze error:', error)
    return NextResponse.json({ error: 'ì½”ë“œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' }, { status: 500 })
  }
}
