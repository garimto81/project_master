/**
 * LLM Client - Google Gemini API
 * ì½”ë“œ ë¶„ì„ì„ ìœ„í•œ LLM í´ë¼ì´ì–¸íŠ¸
 *
 * Issues: #61, #62
 *
 * ì§€ì› ëª¨ë¸:
 * - Gemini 2.0 Flash (ê¸°ë³¸) - ë¹ ë¥´ê³  ì €ë ´
 * - Gemini 1.5 Pro - ë” ë†’ì€ í’ˆì§ˆ
 */

// Gemini API ì„¤ì •
const GEMINI_API_KEY = process.env.GEMINI_API_KEY || ''
const GEMINI_MODEL = process.env.GEMINI_MODEL || 'gemini-2.0-flash'
const TIMEOUT_MS = 30000

interface GeminiRequest {
  contents: Array<{
    parts: Array<{ text: string }>
  }>
  generationConfig?: {
    temperature?: number
    topP?: number
    maxOutputTokens?: number
  }
}

interface GeminiResponse {
  candidates: Array<{
    content: {
      parts: Array<{ text: string }>
    }
    finishReason: string
  }>
  usageMetadata?: {
    promptTokenCount: number
    candidatesTokenCount: number
  }
}

interface ModuleAnalysis {
  title: string
  description: string
  role: string
  inputs: string[]
  outputs: string[]
  relatedModules: string[]
}

// ìºì‹œ (ë™ì¼ ì½”ë“œ ì¬ë¶„ì„ ë°©ì§€)
const analysisCache = new Map<string, ModuleAnalysis>()
const CACHE_TTL = 10 * 60 * 1000 // 10ë¶„

/**
 * Gemini API í˜¸ì¶œ
 */
async function callGemini(prompt: string): Promise<string> {
  if (!GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
  }

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{ parts: [{ text: prompt }] }],
          generationConfig: {
            temperature: 0.3,
            topP: 0.9,
            maxOutputTokens: 512,
          },
        } as GeminiRequest),
        signal: AbortSignal.timeout(TIMEOUT_MS),
      }
    )

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      throw new Error(`Gemini API error: ${response.status} - ${JSON.stringify(errorData)}`)
    }

    const data: GeminiResponse = await response.json()
    return data.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || ''
  } catch (error) {
    console.error('[Gemini] API call failed:', error)
    throw error
  }
}

/**
 * LLM ì„œë²„ ìƒíƒœ í™•ì¸ (Gemini API)
 */
export async function checkOllamaStatus(): Promise<{ available: boolean; models: string[] }> {
  // API í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥ìœ¼ë¡œ í‘œì‹œ
  if (GEMINI_API_KEY) {
    return { available: true, models: [GEMINI_MODEL] }
  }
  return { available: false, models: [] }
}

/**
 * ëª¨ë“ˆ ì œëª© ìƒì„± (Issue #61)
 * ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë¹„ê°œë°œì ì¹œí™”ì ì¸ í•œê¸€ ì œëª© ìƒì„±
 */
export async function generateModuleTitle(
  code: string,
  fileName: string,
  layer: string
): Promise<{ title: string; icon: string }> {
  const cacheKey = `title:${fileName}:${code.slice(0, 100)}`
  const cached = analysisCache.get(cacheKey)
  if (cached) {
    return { title: cached.title, icon: getLayerIcon(layer) }
  }

  const prompt = `ë‹¤ìŒ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ , ë¹„ê°œë°œìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í•œê¸€ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”.

íŒŒì¼ëª…: ${fileName}
ë ˆì´ì–´: ${layer}
ì½”ë“œ:
\`\`\`
${code.slice(0, 1500)}
\`\`\`

ê·œì¹™:
1. 10ì ì´ë‚´ì˜ ê°„ê²°í•œ í•œê¸€ ì œëª©
2. ê¸°ëŠ¥ì„ ëª…í™•íˆ ì„¤ëª…
3. ê¸°ìˆ  ìš©ì–´ ëŒ€ì‹  ì¼ìƒ ìš©ì–´ ì‚¬ìš©
4. ì˜ˆì‹œ: "GitHub ë¡œê·¸ì¸ ì²˜ë¦¬", "ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ", "ê²°ì œ ìŠ¹ì¸"

ì œëª©ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´):`

  try {
    const response = await callGemini(prompt)
    // ì²« ì¤„ë§Œ ì¶”ì¶œ, ë”°ì˜´í‘œ ì œê±°
    const title = response.split('\n')[0].replace(/['"]/g, '').trim()

    // ìºì‹œ ì €ì¥
    analysisCache.set(cacheKey, {
      title,
      description: '',
      role: '',
      inputs: [],
      outputs: [],
      relatedModules: [],
    })

    return { title: title || fileName, icon: getLayerIcon(layer) }
  } catch {
    // Fallback: íŒŒì¼ëª… ê¸°ë°˜ ì œëª©
    return { title: humanizeFileName(fileName), icon: getLayerIcon(layer) }
  }
}

/**
 * ëª¨ë“ˆ ì„¤ëª… ìƒì„± (Issue #62)
 * ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ì„¤ëª… ìƒì„±
 */
export async function generateModuleDescription(
  code: string,
  fileName: string,
  layer: string
): Promise<ModuleAnalysis> {
  const cacheKey = `desc:${fileName}:${code.slice(0, 100)}`
  const cached = analysisCache.get(cacheKey)
  if (cached && cached.description) {
    return cached
  }

  const prompt = `ë‹¤ìŒ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ , ë¹„ê°œë°œìê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•˜ì„¸ìš”.

íŒŒì¼ëª…: ${fileName}
ë ˆì´ì–´: ${layer}
ì½”ë“œ:
\`\`\`
${code.slice(0, 2000)}
\`\`\`

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "title": "10ì ì´ë‚´ í•œê¸€ ì œëª©",
  "role": "ì´ ëª¨ë“ˆì´ í•˜ëŠ” ì¼ (1ë¬¸ì¥)",
  "inputs": ["í•„ìš”í•œ ë°ì´í„° 1", "í•„ìš”í•œ ë°ì´í„° 2"],
  "outputs": ["ê²°ê³¼ë¬¼ 1", "ê²°ê³¼ë¬¼ 2"],
  "relatedModules": ["ì—°ê´€ ëª¨ë“ˆëª… 1", "ì—°ê´€ ëª¨ë“ˆëª… 2"]
}

ê·œì¹™:
1. ë¹„ê°œë°œì ì¹œí™”ì  ìš©ì–´ ì‚¬ìš©
2. ê¸°ìˆ  ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì›ë³¸ í‘œì‹œ
3. ì…ë ¥/ì¶œë ¥ì€ ìµœëŒ€ 3ê°œ`

  try {
    const response = await callGemini(prompt)

    // JSON íŒŒì‹± ì‹œë„
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0])
      const analysis: ModuleAnalysis = {
        title: parsed.title || humanizeFileName(fileName),
        description: parsed.role || '',
        role: parsed.role || '',
        inputs: parsed.inputs || [],
        outputs: parsed.outputs || [],
        relatedModules: parsed.relatedModules || [],
      }

      // ìºì‹œ ì €ì¥
      analysisCache.set(cacheKey, analysis)
      return analysis
    }

    throw new Error('Invalid JSON response')
  } catch {
    // Fallback: ê¸°ë³¸ ì„¤ëª…
    return {
      title: humanizeFileName(fileName),
      description: getDefaultDescription(layer),
      role: getDefaultDescription(layer),
      inputs: [],
      outputs: [],
      relatedModules: [],
    }
  }
}

/**
 * í•¨ìˆ˜ í˜¸ì¶œ ê´€ê³„ ë¶„ì„ (Issue #60)
 * ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì¸ê³¼ê´€ê³„ ì¶”ì¶œ
 */
export async function analyzeFunctionCausality(
  code: string,
  functionName: string
): Promise<{
  triggers: string[]      // ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ì´ë²¤íŠ¸/í•¨ìˆ˜
  effects: string[]       // ì´ í•¨ìˆ˜ê°€ ë°œìƒì‹œí‚¤ëŠ” íš¨ê³¼
  dataFlow: string[]      // ë°ì´í„° íë¦„ ì„¤ëª…
}> {
  const prompt = `ë‹¤ìŒ í•¨ìˆ˜ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

í•¨ìˆ˜ëª…: ${functionName}
ì½”ë“œ:
\`\`\`
${code.slice(0, 1500)}
\`\`\`

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "triggers": ["ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” íŠ¸ë¦¬ê±° (ì˜ˆ: ë²„íŠ¼ í´ë¦­, í˜ì´ì§€ ë¡œë“œ)"],
  "effects": ["ì´ í•¨ìˆ˜ê°€ ë°œìƒì‹œí‚¤ëŠ” íš¨ê³¼ (ì˜ˆ: ë°ì´í„° ì €ì¥, í™”ë©´ ê°±ì‹ )"],
  "dataFlow": ["ë°ì´í„° íë¦„ ì„¤ëª… (ì˜ˆ: ì‚¬ìš©ì ì…ë ¥ -> ì„œë²„ ì „ì†¡ -> ê²°ê³¼ í‘œì‹œ)"]
}

ê·œì¹™:
1. ë¹„ê°œë°œì ì¹œí™”ì  ìš©ì–´
2. ê° í•­ëª© ìµœëŒ€ 3ê°œ
3. í™”ì‚´í‘œ(->)ë¡œ íë¦„ í‘œì‹œ`

  try {
    const response = await callGemini(prompt)

    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0])
      return {
        triggers: parsed.triggers || [],
        effects: parsed.effects || [],
        dataFlow: parsed.dataFlow || [],
      }
    }

    throw new Error('Invalid JSON response')
  } catch {
    return {
      triggers: [],
      effects: [],
      dataFlow: [],
    }
  }
}

/**
 * ë°°ì¹˜ ë¶„ì„ (ì—¬ëŸ¬ ëª¨ë“ˆ ë™ì‹œ ë¶„ì„)
 */
export async function batchAnalyzeModules(
  modules: Array<{ code: string; fileName: string; layer: string }>
): Promise<Map<string, ModuleAnalysis>> {
  const results = new Map<string, ModuleAnalysis>()

  // ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 3ê°œ ë™ì‹œ)
  const BATCH_SIZE = 3
  for (let i = 0; i < modules.length; i += BATCH_SIZE) {
    const batch = modules.slice(i, i + BATCH_SIZE)

    const batchResults = await Promise.allSettled(
      batch.map(async (mod) => {
        const analysis = await generateModuleDescription(mod.code, mod.fileName, mod.layer)
        return { fileName: mod.fileName, analysis }
      })
    )

    for (const result of batchResults) {
      if (result.status === 'fulfilled') {
        results.set(result.value.fileName, result.value.analysis)
      }
    }
  }

  return results
}

// ============================================================
// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
// ============================================================

function getLayerIcon(layer: string): string {
  const icons: Record<string, string> = {
    ui: 'ğŸ–¥ï¸',
    logic: 'âš™ï¸',
    api: 'ğŸŒ',
    server: 'ğŸŒ',
    data: 'ğŸ’¾',
    lib: 'ğŸ”§',
  }
  return icons[layer] || 'ğŸ“„'
}

function humanizeFileName(fileName: string): string {
  // CamelCase -> ê³µë°± ë¶„ë¦¬ -> í•œê¸€í™”
  const words = fileName
    .replace(/\.(tsx?|jsx?|py)$/, '')
    .replace(/([a-z])([A-Z])/g, '$1 $2')
    .replace(/[-_]/g, ' ')
    .toLowerCase()
    .split(' ')

  const translations: Record<string, string> = {
    login: 'ë¡œê·¸ì¸',
    logout: 'ë¡œê·¸ì•„ì›ƒ',
    auth: 'ì¸ì¦',
    user: 'ì‚¬ìš©ì',
    dashboard: 'ëŒ€ì‹œë³´ë“œ',
    home: 'í™ˆ',
    page: 'í˜ì´ì§€',
    component: 'ì»´í¬ë„ŒíŠ¸',
    form: 'ì…ë ¥í¼',
    list: 'ëª©ë¡',
    detail: 'ìƒì„¸',
    create: 'ìƒì„±',
    edit: 'ìˆ˜ì •',
    delete: 'ì‚­ì œ',
    search: 'ê²€ìƒ‰',
    filter: 'í•„í„°',
    route: 'ë¼ìš°íŠ¸',
    handler: 'ì²˜ë¦¬ê¸°',
    service: 'ì„œë¹„ìŠ¤',
    hook: 'í›…',
    util: 'ìœ í‹¸',
    helper: 'í—¬í¼',
  }

  const translated = words.map(w => translations[w] || w)
  return translated.join(' ')
}

function getDefaultDescription(layer: string): string {
  const descriptions: Record<string, string> = {
    ui: 'ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì§€ëŠ” í™”ë©´ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.',
    logic: 'ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    api: 'ì„œë²„ì™€ í†µì‹ í•˜ëŠ” API ëª¨ë“ˆì…ë‹ˆë‹¤.',
    server: 'ì„œë²„ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    data: 'ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    lib: 'ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆì…ë‹ˆë‹¤.',
  }
  return descriptions[layer] || 'ê¸°ëŠ¥ ëª¨ë“ˆì…ë‹ˆë‹¤.'
}

// ìºì‹œ ì •ë¦¬ (10ë¶„ë§ˆë‹¤)
setInterval(() => {
  analysisCache.clear()
}, CACHE_TTL)

export { analysisCache }
