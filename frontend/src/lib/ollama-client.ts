/**
 * Ollama Local LLM Client
 * Local Ollama (Qwen3) ëª¨ë¸ì„ ì‚¬ìš©í•œ ì½”ë“œ ë¶„ì„
 *
 * Issues: #61, #62
 */

// Ollama API ì„¤ì •
const OLLAMA_BASE_URL = process.env.OLLAMA_URL || 'http://localhost:11434'
const DEFAULT_MODEL = process.env.OLLAMA_MODEL || 'qwen3'
const TIMEOUT_MS = 30000

interface OllamaGenerateRequest {
  model: string
  prompt: string
  stream?: boolean
  options?: {
    temperature?: number
    top_p?: number
    num_predict?: number
  }
}

interface OllamaGenerateResponse {
  model: string
  response: string
  done: boolean
  context?: number[]
  total_duration?: number
  load_duration?: number
  prompt_eval_count?: number
  eval_count?: number
}

interface ModuleAnalysis {
  title: string
  description: string
  role: string
  inputs: string[]
  outputs: string[]
  relatedModules: string[]
}

// ìºì‹œ (ë™ì¼ ì½”ë“œ ì¬ë¶„ì„ ë°©ì§€)
const analysisCache = new Map<string, ModuleAnalysis>()
const CACHE_TTL = 10 * 60 * 1000 // 10ë¶„

/**
 * Ollama API í˜¸ì¶œ
 */
async function callOllama(prompt: string, model: string = DEFAULT_MODEL): Promise<string> {
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model,
        prompt,
        stream: false,
        options: {
          temperature: 0.3,
          top_p: 0.9,
          num_predict: 512,
        },
      } as OllamaGenerateRequest),
      signal: AbortSignal.timeout(TIMEOUT_MS),
    })

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.status}`)
    }

    const data: OllamaGenerateResponse = await response.json()
    return data.response.trim()
  } catch (error) {
    console.error('[Ollama] API call failed:', error)
    throw error
  }
}

/**
 * Ollama ì„œë²„ ìƒíƒœ í™•ì¸
 */
export async function checkOllamaStatus(): Promise<{ available: boolean; models: string[] }> {
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
      signal: AbortSignal.timeout(5000),
    })

    if (!response.ok) {
      return { available: false, models: [] }
    }

    const data = await response.json()
    const models = (data.models || []).map((m: { name: string }) => m.name)

    return { available: true, models }
  } catch {
    return { available: false, models: [] }
  }
}

/**
 * ëª¨ë“ˆ ì œëª© ìƒì„± (Issue #61)
 * ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë¹„ê°œë°œì ì¹œí™”ì ì¸ í•œê¸€ ì œëª© ìƒì„±
 */
export async function generateModuleTitle(
  code: string,
  fileName: string,
  layer: string
): Promise<{ title: string; icon: string }> {
  const cacheKey = `title:${fileName}:${code.slice(0, 100)}`
  const cached = analysisCache.get(cacheKey)
  if (cached) {
    return { title: cached.title, icon: getLayerIcon(layer) }
  }

  const prompt = `ë‹¤ìŒ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ , ë¹„ê°œë°œìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í•œê¸€ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”.

íŒŒì¼ëª…: ${fileName}
ë ˆì´ì–´: ${layer}
ì½”ë“œ:
\`\`\`
${code.slice(0, 1500)}
\`\`\`

ê·œì¹™:
1. 10ì ì´ë‚´ì˜ ê°„ê²°í•œ í•œê¸€ ì œëª©
2. ê¸°ëŠ¥ì„ ëª…í™•íˆ ì„¤ëª…
3. ê¸°ìˆ  ìš©ì–´ ëŒ€ì‹  ì¼ìƒ ìš©ì–´ ì‚¬ìš©
4. ì˜ˆì‹œ: "GitHub ë¡œê·¸ì¸ ì²˜ë¦¬", "ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ", "ê²°ì œ ìŠ¹ì¸"

ì œëª©ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´):`

  try {
    const response = await callOllama(prompt)
    // ì²« ì¤„ë§Œ ì¶”ì¶œ, ë”°ì˜´í‘œ ì œê±°
    const title = response.split('\n')[0].replace(/['"]/g, '').trim()

    // ìºì‹œ ì €ì¥
    analysisCache.set(cacheKey, {
      title,
      description: '',
      role: '',
      inputs: [],
      outputs: [],
      relatedModules: [],
    })

    return { title: title || fileName, icon: getLayerIcon(layer) }
  } catch {
    // Fallback: íŒŒì¼ëª… ê¸°ë°˜ ì œëª©
    return { title: humanizeFileName(fileName), icon: getLayerIcon(layer) }
  }
}

/**
 * ëª¨ë“ˆ ì„¤ëª… ìƒì„± (Issue #62)
 * ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ì„¤ëª… ìƒì„±
 */
export async function generateModuleDescription(
  code: string,
  fileName: string,
  layer: string
): Promise<ModuleAnalysis> {
  const cacheKey = `desc:${fileName}:${code.slice(0, 100)}`
  const cached = analysisCache.get(cacheKey)
  if (cached && cached.description) {
    return cached
  }

  const prompt = `ë‹¤ìŒ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ , ë¹„ê°œë°œìê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•˜ì„¸ìš”.

íŒŒì¼ëª…: ${fileName}
ë ˆì´ì–´: ${layer}
ì½”ë“œ:
\`\`\`
${code.slice(0, 2000)}
\`\`\`

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "title": "10ì ì´ë‚´ í•œê¸€ ì œëª©",
  "role": "ì´ ëª¨ë“ˆì´ í•˜ëŠ” ì¼ (1ë¬¸ì¥)",
  "inputs": ["í•„ìš”í•œ ë°ì´í„° 1", "í•„ìš”í•œ ë°ì´í„° 2"],
  "outputs": ["ê²°ê³¼ë¬¼ 1", "ê²°ê³¼ë¬¼ 2"],
  "relatedModules": ["ì—°ê´€ ëª¨ë“ˆëª… 1", "ì—°ê´€ ëª¨ë“ˆëª… 2"]
}

ê·œì¹™:
1. ë¹„ê°œë°œì ì¹œí™”ì  ìš©ì–´ ì‚¬ìš©
2. ê¸°ìˆ  ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì›ë³¸ í‘œì‹œ
3. ì…ë ¥/ì¶œë ¥ì€ ìµœëŒ€ 3ê°œ`

  try {
    const response = await callOllama(prompt)

    // JSON íŒŒì‹± ì‹œë„
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0])
      const analysis: ModuleAnalysis = {
        title: parsed.title || humanizeFileName(fileName),
        description: parsed.role || '',
        role: parsed.role || '',
        inputs: parsed.inputs || [],
        outputs: parsed.outputs || [],
        relatedModules: parsed.relatedModules || [],
      }

      // ìºì‹œ ì €ì¥
      analysisCache.set(cacheKey, analysis)
      return analysis
    }

    throw new Error('Invalid JSON response')
  } catch {
    // Fallback: ê¸°ë³¸ ì„¤ëª…
    return {
      title: humanizeFileName(fileName),
      description: getDefaultDescription(layer),
      role: getDefaultDescription(layer),
      inputs: [],
      outputs: [],
      relatedModules: [],
    }
  }
}

/**
 * í•¨ìˆ˜ í˜¸ì¶œ ê´€ê³„ ë¶„ì„ (Issue #60)
 * ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì¸ê³¼ê´€ê³„ ì¶”ì¶œ
 */
export async function analyzeFunctionCausality(
  code: string,
  functionName: string
): Promise<{
  triggers: string[]      // ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ì´ë²¤íŠ¸/í•¨ìˆ˜
  effects: string[]       // ì´ í•¨ìˆ˜ê°€ ë°œìƒì‹œí‚¤ëŠ” íš¨ê³¼
  dataFlow: string[]      // ë°ì´í„° íë¦„ ì„¤ëª…
}> {
  const prompt = `ë‹¤ìŒ í•¨ìˆ˜ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

í•¨ìˆ˜ëª…: ${functionName}
ì½”ë“œ:
\`\`\`
${code.slice(0, 1500)}
\`\`\`

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "triggers": ["ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” íŠ¸ë¦¬ê±° (ì˜ˆ: ë²„íŠ¼ í´ë¦­, í˜ì´ì§€ ë¡œë“œ)"],
  "effects": ["ì´ í•¨ìˆ˜ê°€ ë°œìƒì‹œí‚¤ëŠ” íš¨ê³¼ (ì˜ˆ: ë°ì´í„° ì €ì¥, í™”ë©´ ê°±ì‹ )"],
  "dataFlow": ["ë°ì´í„° íë¦„ ì„¤ëª… (ì˜ˆ: ì‚¬ìš©ì ì…ë ¥ -> ì„œë²„ ì „ì†¡ -> ê²°ê³¼ í‘œì‹œ)"]
}

ê·œì¹™:
1. ë¹„ê°œë°œì ì¹œí™”ì  ìš©ì–´
2. ê° í•­ëª© ìµœëŒ€ 3ê°œ
3. í™”ì‚´í‘œ(->)ë¡œ íë¦„ í‘œì‹œ`

  try {
    const response = await callOllama(prompt)

    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0])
      return {
        triggers: parsed.triggers || [],
        effects: parsed.effects || [],
        dataFlow: parsed.dataFlow || [],
      }
    }

    throw new Error('Invalid JSON response')
  } catch {
    return {
      triggers: [],
      effects: [],
      dataFlow: [],
    }
  }
}

/**
 * ë°°ì¹˜ ë¶„ì„ (ì—¬ëŸ¬ ëª¨ë“ˆ ë™ì‹œ ë¶„ì„)
 */
export async function batchAnalyzeModules(
  modules: Array<{ code: string; fileName: string; layer: string }>
): Promise<Map<string, ModuleAnalysis>> {
  const results = new Map<string, ModuleAnalysis>()

  // ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 3ê°œ ë™ì‹œ)
  const BATCH_SIZE = 3
  for (let i = 0; i < modules.length; i += BATCH_SIZE) {
    const batch = modules.slice(i, i + BATCH_SIZE)

    const batchResults = await Promise.allSettled(
      batch.map(async (mod) => {
        const analysis = await generateModuleDescription(mod.code, mod.fileName, mod.layer)
        return { fileName: mod.fileName, analysis }
      })
    )

    for (const result of batchResults) {
      if (result.status === 'fulfilled') {
        results.set(result.value.fileName, result.value.analysis)
      }
    }
  }

  return results
}

// ============================================================
// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
// ============================================================

function getLayerIcon(layer: string): string {
  const icons: Record<string, string> = {
    ui: 'ğŸ–¥ï¸',
    logic: 'âš™ï¸',
    api: 'ğŸŒ',
    server: 'ğŸŒ',
    data: 'ğŸ’¾',
    lib: 'ğŸ”§',
  }
  return icons[layer] || 'ğŸ“„'
}

function humanizeFileName(fileName: string): string {
  // CamelCase -> ê³µë°± ë¶„ë¦¬ -> í•œê¸€í™”
  const words = fileName
    .replace(/\.(tsx?|jsx?|py)$/, '')
    .replace(/([a-z])([A-Z])/g, '$1 $2')
    .replace(/[-_]/g, ' ')
    .toLowerCase()
    .split(' ')

  const translations: Record<string, string> = {
    login: 'ë¡œê·¸ì¸',
    logout: 'ë¡œê·¸ì•„ì›ƒ',
    auth: 'ì¸ì¦',
    user: 'ì‚¬ìš©ì',
    dashboard: 'ëŒ€ì‹œë³´ë“œ',
    home: 'í™ˆ',
    page: 'í˜ì´ì§€',
    component: 'ì»´í¬ë„ŒíŠ¸',
    form: 'ì…ë ¥í¼',
    list: 'ëª©ë¡',
    detail: 'ìƒì„¸',
    create: 'ìƒì„±',
    edit: 'ìˆ˜ì •',
    delete: 'ì‚­ì œ',
    search: 'ê²€ìƒ‰',
    filter: 'í•„í„°',
    route: 'ë¼ìš°íŠ¸',
    handler: 'ì²˜ë¦¬ê¸°',
    service: 'ì„œë¹„ìŠ¤',
    hook: 'í›…',
    util: 'ìœ í‹¸',
    helper: 'í—¬í¼',
  }

  const translated = words.map(w => translations[w] || w)
  return translated.join(' ')
}

function getDefaultDescription(layer: string): string {
  const descriptions: Record<string, string> = {
    ui: 'ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì§€ëŠ” í™”ë©´ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.',
    logic: 'ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    api: 'ì„œë²„ì™€ í†µì‹ í•˜ëŠ” API ëª¨ë“ˆì…ë‹ˆë‹¤.',
    server: 'ì„œë²„ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    data: 'ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    lib: 'ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆì…ë‹ˆë‹¤.',
  }
  return descriptions[layer] || 'ê¸°ëŠ¥ ëª¨ë“ˆì…ë‹ˆë‹¤.'
}

// ìºì‹œ ì •ë¦¬ (10ë¶„ë§ˆë‹¤)
setInterval(() => {
  analysisCache.clear()
}, CACHE_TTL)

export { analysisCache }
