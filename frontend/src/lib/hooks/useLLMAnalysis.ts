/**
 * LLM ë¶„ì„ Hook
 * Issues: #61 (ëª¨ë“ˆ ì œëª©), #62 (ëª¨ë“ˆ ì„¤ëª…)
 *
 * Local Ollama (Qwen3) ëª¨ë¸ì„ ì‚¬ìš©í•œ ì½”ë“œ ë¶„ì„
 */

import { useState, useCallback } from 'react'

interface ModuleAnalysis {
  path: string
  title: string
  description?: string
  role?: string
  inputs?: string[]
  outputs?: string[]
  relatedModules?: string[]
  icon?: string
}

interface LLMStatus {
  available: boolean
  models: string[]
}

interface UseLLMAnalysisReturn {
  // ìƒíƒœ
  isAnalyzing: boolean
  error: string | null
  llmStatus: LLMStatus | null

  // ë¶„ì„ ê²°ê³¼
  moduleAnalyses: Map<string, ModuleAnalysis>

  // ì•¡ì…˜
  checkLLMStatus: () => Promise<LLMStatus>
  analyzeModuleTitles: (repo: string, files: Array<{ path: string; layer: string }>) => Promise<ModuleAnalysis[]>
  analyzeModuleDescriptions: (repo: string, files: Array<{ path: string; layer: string }>) => Promise<ModuleAnalysis[]>
  clearCache: () => void
}

export function useLLMAnalysis(): UseLLMAnalysisReturn {
  const [isAnalyzing, setIsAnalyzing] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [llmStatus, setLLMStatus] = useState<LLMStatus | null>(null)
  const [moduleAnalyses, setModuleAnalyses] = useState<Map<string, ModuleAnalysis>>(new Map())

  /**
   * Ollama ì„œë²„ ìƒíƒœ í™•ì¸
   */
  const checkLLMStatus = useCallback(async (): Promise<LLMStatus> => {
    try {
      const res = await fetch('/api/logic-flow/llm-analyze')
      if (!res.ok) {
        const status = { available: false, models: [] }
        setLLMStatus(status)
        return status
      }

      const data = await res.json()
      const status = {
        available: data.ollama?.available || false,
        models: data.ollama?.models || [],
      }
      setLLMStatus(status)
      return status
    } catch {
      const status = { available: false, models: [] }
      setLLMStatus(status)
      return status
    }
  }, [])

  /**
   * ëª¨ë“ˆ ì œëª© ë¶„ì„ (Issue #61)
   */
  const analyzeModuleTitles = useCallback(async (
    repo: string,
    files: Array<{ path: string; layer: string }>
  ): Promise<ModuleAnalysis[]> => {
    if (files.length === 0) return []

    setIsAnalyzing(true)
    setError(null)

    try {
      const res = await fetch('/api/logic-flow/llm-analyze', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          repo,
          files,
          mode: 'title',
        }),
      })

      if (!res.ok) {
        const data = await res.json()
        // Ollama ì„œë²„ ë¯¸ì‹¤í–‰ ì‹œ fallback
        if (res.status === 503) {
          console.warn('[LLM] Ollama ì„œë²„ ë¯¸ì‹¤í–‰, fallback ì‚¬ìš©')
          return files.map(f => ({
            path: f.path,
            title: f.path.split('/').pop()?.replace(/\.(ts|tsx|js|jsx)$/, '') || f.path,
            icon: getLayerIcon(f.layer),
          }))
        }
        throw new Error(data.error || 'LLM ë¶„ì„ ì‹¤íŒ¨')
      }

      const data = await res.json()
      const results: ModuleAnalysis[] = data.results || []

      // ìºì‹œ ì—…ë°ì´íŠ¸
      setModuleAnalyses(prev => {
        const updated = new Map(prev)
        for (const result of results) {
          updated.set(result.path, result)
        }
        return updated
      })

      return results
    } catch (err) {
      const message = err instanceof Error ? err.message : 'LLM ë¶„ì„ ì‹¤íŒ¨'
      setError(message)
      console.error('[LLM] Title analysis error:', err)

      // Fallback: íŒŒì¼ëª… ê¸°ë°˜ ì œëª©
      return files.map(f => ({
        path: f.path,
        title: f.path.split('/').pop()?.replace(/\.(ts|tsx|js|jsx)$/, '') || f.path,
        icon: getLayerIcon(f.layer),
      }))
    } finally {
      setIsAnalyzing(false)
    }
  }, [])

  /**
   * ëª¨ë“ˆ ì„¤ëª… ë¶„ì„ (Issue #62)
   */
  const analyzeModuleDescriptions = useCallback(async (
    repo: string,
    files: Array<{ path: string; layer: string }>
  ): Promise<ModuleAnalysis[]> => {
    if (files.length === 0) return []

    setIsAnalyzing(true)
    setError(null)

    try {
      const res = await fetch('/api/logic-flow/llm-analyze', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          repo,
          files,
          mode: 'description',
        }),
      })

      if (!res.ok) {
        const data = await res.json()
        if (res.status === 503) {
          console.warn('[LLM] Ollama ì„œë²„ ë¯¸ì‹¤í–‰, fallback ì‚¬ìš©')
          return files.map(f => ({
            path: f.path,
            title: f.path.split('/').pop()?.replace(/\.(ts|tsx|js|jsx)$/, '') || f.path,
            description: getDefaultDescription(f.layer),
          }))
        }
        throw new Error(data.error || 'LLM ë¶„ì„ ì‹¤íŒ¨')
      }

      const data = await res.json()
      const results: ModuleAnalysis[] = data.results || []

      // ìºì‹œ ì—…ë°ì´íŠ¸
      setModuleAnalyses(prev => {
        const updated = new Map(prev)
        for (const result of results) {
          updated.set(result.path, result)
        }
        return updated
      })

      return results
    } catch (err) {
      const message = err instanceof Error ? err.message : 'LLM ë¶„ì„ ì‹¤íŒ¨'
      setError(message)
      console.error('[LLM] Description analysis error:', err)

      // Fallback: ê¸°ë³¸ ì„¤ëª…
      return files.map(f => ({
        path: f.path,
        title: f.path.split('/').pop()?.replace(/\.(ts|tsx|js|jsx)$/, '') || f.path,
        description: getDefaultDescription(f.layer),
      }))
    } finally {
      setIsAnalyzing(false)
    }
  }, [])

  /**
   * ìºì‹œ ì´ˆê¸°í™”
   */
  const clearCache = useCallback(() => {
    setModuleAnalyses(new Map())
    setError(null)
  }, [])

  return {
    isAnalyzing,
    error,
    llmStatus,
    moduleAnalyses,
    checkLLMStatus,
    analyzeModuleTitles,
    analyzeModuleDescriptions,
    clearCache,
  }
}

// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
function getLayerIcon(layer: string): string {
  const icons: Record<string, string> = {
    ui: 'ğŸ–¥ï¸',
    logic: 'âš™ï¸',
    api: 'ğŸŒ',
    server: 'ğŸŒ',
    data: 'ğŸ’¾',
    lib: 'ğŸ”§',
  }
  return icons[layer] || 'ğŸ“„'
}

function getDefaultDescription(layer: string): string {
  const descriptions: Record<string, string> = {
    ui: 'ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì§€ëŠ” í™”ë©´ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.',
    logic: 'ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    api: 'ì„œë²„ì™€ í†µì‹ í•˜ëŠ” API ëª¨ë“ˆì…ë‹ˆë‹¤.',
    server: 'ì„œë²„ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    data: 'ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.',
    lib: 'ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆì…ë‹ˆë‹¤.',
  }
  return descriptions[layer] || 'ê¸°ëŠ¥ ëª¨ë“ˆì…ë‹ˆë‹¤.'
}
